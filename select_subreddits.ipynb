{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for selecting all comments ever in a particular set of subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlC = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit = sqlC.read.parquet(\"all_comments.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- approved_at_utc: string (nullable = true)\n",
      " |-- approved_by: string (nullable = true)\n",
      " |-- archived: boolean (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_cakeday: boolean (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- banned_at_utc: string (nullable = true)\n",
      " |-- banned_by: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- body_html: string (nullable = true)\n",
      " |-- can_gild: boolean (nullable = true)\n",
      " |-- can_mod_post: boolean (nullable = true)\n",
      " |-- collapsed: boolean (nullable = true)\n",
      " |-- collapsed_reason: string (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created: long (nullable = true)\n",
      " |-- created_utc: string (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- downs: long (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- is_submitter: boolean (nullable = true)\n",
      " |-- likes: string (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- mod_reports: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- num_reports: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- removal_reason: string (nullable = true)\n",
      " |-- replies: string (nullable = true)\n",
      " |-- report_reasons: string (nullable = true)\n",
      " |-- retrieved_on: long (nullable = true)\n",
      " |-- saved: boolean (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- score_hidden: boolean (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- ups: long (nullable = true)\n",
      " |-- user_reports: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select just the columns we want to work with\n",
    "- specifically, exclude columns that have sub-columns to them because they're a pain to work with if we don't need their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit = reddit[['approved_at_utc',  'approved_by', 'archived', 'author', \n",
    "                 'author_cakeday', 'author_flair_css_class', 'author_flair_text',\n",
    "                 'banned_at_utc', 'banned_by',  'body',  'can_gild',\n",
    "                 'can_mod_post', 'collapsed',  'collapsed_reason', 'controversiality',\n",
    "                 'created', 'created_utc', 'distinguished', 'downs',  'edited',\n",
    "                 'gilded',  'id', 'is_submitter', 'likes', 'link_id', 'name', \n",
    "                 'num_reports', 'parent_id', 'removal_reason', 'replies', \n",
    "                 'report_reasons', 'retrieved_on', 'saved', 'score', 'score_hidden',\n",
    "                 'stickied', 'subreddit', 'subreddit_id', 'ups']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up text\n",
    "- Reddit lets users type almost anything. This can be a major pain down the road. To help, this code replaces all of the newlines, carriage returns, and tabs with spaces. \n",
    "    - yes, some information is lost this way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit = reddit.withColumn('body', regexp_replace('body', '\\n', ' '))\n",
    "reddit = reddit.withColumn('body', regexp_replace('body', '\\r', ' '))\n",
    "reddit = reddit.withColumn('body', regexp_replace('body', '\\t', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get a count of how many posts are in each subreddit\n",
    "- this can help us decide which ones to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|          subreddit|   count|\n",
      "+-------------------+--------+\n",
      "|              anime|11324720|\n",
      "|         MensRights| 3527064|\n",
      "|         MLBTheShow|  762202|\n",
      "|             travel| 1647254|\n",
      "|UnresolvedMysteries|  655796|\n",
      "|           arumba07|   23084|\n",
      "|           lacrosse|  123522|\n",
      "|         QuotesPorn|  339011|\n",
      "|         ArtHistory|   25659|\n",
      "|            ukraina|  673181|\n",
      "+-------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = reddit.groupby('subreddit').count()\n",
    "tmp.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List subreddits of interest, see their post count\n",
    "- case sensitive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "|      subreddit|   count|\n",
      "+---------------+--------+\n",
      "|       politics|61748124|\n",
      "|    Libertarian| 3990229|\n",
      "|      socialism| 1110657|\n",
      "|  FULLCOMMUNISM|  494840|\n",
      "|NeutralPolitics|  342213|\n",
      "|     Republican|  333246|\n",
      "|    progressive|  247961|\n",
      "|      democrats|  172526|\n",
      "|        Liberal|  152893|\n",
      "|      communism|  123248|\n",
      "|     GreenParty|   15215|\n",
      "|    republicans|   11949|\n",
      "|   demsocialist|    5428|\n",
      "+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "li = ['politics', \n",
    "      'Republican', 'republicans', #'askaconservative', 'CollegeRepublicans', 'askarepublican',\n",
    "      'democrats', #'AskDemocrats', 'Democrat', 'CollegeDemocrats',\n",
    "      'GreenParty',\n",
    "      'Libertarian', #'AskLibertarians',\n",
    "      'Liberal', #'AskALiberal', \n",
    "      'progressive',\n",
    "      'socialism', #'AskASocialist',\n",
    "      'demsocialist',\n",
    "      'communism', 'FULLCOMMUNISM', #'communists', 'Communist', \n",
    "      #'votethirdparty',\n",
    "      'NeutralPolitics'\n",
    "     ]\n",
    "\n",
    "tmp.filter(tmp.subreddit.isin(li)).sort('count', ascending=False).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and save the data from each subrddit separately\n",
    "- First, filter (select where) the data so that we only have the subreddits we care about. Tell pyspark to cache that result for future reuse. This makes the rest of the searches after it faster.\n",
    "    - pyspark actually uses lazy evaluation, so this doesn't run until the first call to `short_reddit.filter()`. That means the first loop is slow, but the loops after it go faster. \n",
    "- Save everything to a tsv file, one per subreddit\n",
    "    - note the headers are off by default\n",
    "    - note this actually saves to a folder full of tsv files (one for each partition). That's a spark thing good for spark but bad for other programs. We'll have to merge them outside this script. (There are ways to merge them here, but if the file is bigger than the JVM memory it throws errors. Easier to fix outside where that doesn't happen.)\n",
    "- write settings\n",
    "    - `mode('overwrite')` replaces the files if they exist already. Saves us from \"file already exists\" errors.\n",
    "    - `header=True` is needed because by default CSVs don't have headers here.\n",
    "    - `escapeQuotes=False` seems like a strange option, but with it off, the files get read in by pandas okay. With it on pandas gives parsing errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making short...\n",
      "making politics\n",
      "making Republican\n",
      "making republicans\n",
      "making democrats\n",
      "making GreenParty\n",
      "making Libertarian\n",
      "making Liberal\n",
      "making progressive\n",
      "making socialism\n",
      "making demsocialist\n",
      "making communism\n",
      "making FULLCOMMUNISM\n",
      "making NeutralPolitics\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"making short...\")\n",
    "short_reddit = reddit.filter(reddit.subreddit.isin(li))\n",
    "short_reddit.cache()\n",
    "\n",
    "for l in li:\n",
    "    print 'making', l\n",
    "    result = short_reddit.filter(short_reddit.subreddit == l)\n",
    "    result.write.mode('overwrite').csv(l+'.tsv.parts', sep='\\t', \n",
    "                                       header=True, escapeQuotes=False)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same as above, but with a different list of subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|     subreddit|  count|\n",
      "+--------------+-------+\n",
      "|          dogs|1504097|\n",
      "|          cats|1479661|\n",
      "|   Dogtraining| 319811|\n",
      "|CatsStandingUp| 299892|\n",
      "|   dogpictures| 187653|\n",
      "|  StartledCats|  90970|\n",
      "|       CatGifs|  23750|\n",
      "|       puppies|  21052|\n",
      "+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "li = ['cats', #'CatsonGlass', 'CatLoaf', 'Kittens', 'Meow_irl',\n",
    "      'CatGifs', 'StartledCats', #'StuffOnCats', \n",
    "      'CatsStandingUp',\n",
    "      'dogs', 'dogpictures', #'dogswithjobs', \n",
    "      'Dogtraining', #'DOG', \n",
    "      'puppies'#, 'dogswearinghats'\n",
    "     ]\n",
    "\n",
    "tmp.filter(tmp.subreddit.isin(li)).sort('count', ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making short...\n",
      "making cats\n",
      "making CatGifs\n",
      "making StartledCats\n",
      "making CatsStandingUp\n",
      "making dogs\n",
      "making dogpictures\n",
      "making Dogtraining\n",
      "making puppies\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"making short...\")\n",
    "short_reddit = reddit.filter(reddit.subreddit.isin(li))\n",
    "short_reddit.cache()\n",
    "\n",
    "for l in li:\n",
    "    print 'making', l\n",
    "    result = short_reddit.filter(short_reddit.subreddit == l)\n",
    "    result.write.mode('overwrite').csv(l+'.tsv.parts', sep='\\t', \n",
    "                                       header=True, escapeQuotes=False)\n",
    "    #df = result.toPandas()\n",
    "    #df.to_csv(l+'.tsv', sep='\\t', index=False)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = reddit.filter(reddit.subreddit == 'CatGifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.write.mode('overwrite').csv('CatGifs.tsv', sep='\\t', header=True, escapeQuotes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "print 'done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
