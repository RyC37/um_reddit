{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for selecting all comments ever in a particular set of subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlC = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = sqlC.read.parquet(\"all_comments.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- approved_at_utc: string (nullable = true)\n",
      " |-- approved_by: string (nullable = true)\n",
      " |-- archived: boolean (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_cakeday: boolean (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- banned_at_utc: string (nullable = true)\n",
      " |-- banned_by: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- body_html: string (nullable = true)\n",
      " |-- can_gild: boolean (nullable = true)\n",
      " |-- can_mod_post: boolean (nullable = true)\n",
      " |-- collapsed: boolean (nullable = true)\n",
      " |-- collapsed_reason: string (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created: long (nullable = true)\n",
      " |-- created_utc: string (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- downs: long (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- is_submitter: boolean (nullable = true)\n",
      " |-- likes: string (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- mod_reports: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- num_reports: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- removal_reason: string (nullable = true)\n",
      " |-- replies: string (nullable = true)\n",
      " |-- report_reasons: string (nullable = true)\n",
      " |-- retrieved_on: long (nullable = true)\n",
      " |-- saved: boolean (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- score_hidden: boolean (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- ups: long (nullable = true)\n",
      " |-- user_reports: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select just the columns we want to work with\n",
    "- specifically, exclude columns that have sub-columns to them because they're a pain to work with if we don't need their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit = reddit[['approved_at_utc',  'approved_by', 'archived', 'author', \n",
    "                 'author_cakeday', 'author_flair_css_class', 'author_flair_text',\n",
    "                 'banned_at_utc', 'banned_by',  'body',  'can_gild',\n",
    "                 'can_mod_post', 'collapsed',  'collapsed_reason', 'controversiality',\n",
    "                 'created', 'created_utc', 'distinguished', 'downs',  'edited',\n",
    "                 'gilded',  'id', 'is_submitter', 'likes', 'link_id', 'name', \n",
    "                 'num_reports', 'parent_id', 'removal_reason', 'replies', \n",
    "                 'report_reasons', 'retrieved_on', 'saved', 'score', 'score_hidden',\n",
    "                 'stickied', 'subreddit', 'subreddit_id', 'ups']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace all the newlines in the comment text with spaces.\n",
    "- saves a huge amount of headache with file formats and quoting\n",
    "- yes, some information is lost this way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit = reddit.withColumn('body', regexp_replace('body', '\\n', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get a count of how many posts are in each subreddit\n",
    "- this can help us decide which ones to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = reddit.groupby('subreddit').count()\n",
    "tmp.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List subreddits of interest, see their post count\n",
    "- case sensitive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|       subreddit|   count|\n",
      "+----------------+--------+\n",
      "|        politics|61748124|\n",
      "|     Libertarian| 3990229|\n",
      "|       socialism| 1110657|\n",
      "|   FULLCOMMUNISM|  494840|\n",
      "| NeutralPolitics|  342213|\n",
      "|      Republican|  333246|\n",
      "|     progressive|  247961|\n",
      "|       democrats|  172526|\n",
      "|         Liberal|  152893|\n",
      "|       communism|  123248|\n",
      "|askaconservative|   80139|\n",
      "|     AskALiberal|   50169|\n",
      "|      GreenParty|   15215|\n",
      "| AskLibertarians|   12489|\n",
      "|     republicans|   11949|\n",
      "|    demsocialist|    5428|\n",
      "|    AskDemocrats|    4608|\n",
      "|      communists|    1800|\n",
      "|        Democrat|    1462|\n",
      "|  votethirdparty|     408|\n",
      "+----------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "li = ['politics', \n",
    "      'Republican', 'republicans', 'CollegeRepublicans', 'askaconservative', \n",
    "      'askarepublican',\n",
    "      'Democrat', 'democrats', 'CollegeDemocrats', 'AskDemocrats',\n",
    "      'GreenParty',\n",
    "      'Libertarian', 'AskLibertarians',\n",
    "      'Liberal', 'AskALiberal', \n",
    "      'progressive',\n",
    "      'socialism', 'AskASocialist',\n",
    "      'demsocialist',\n",
    "      'communism', 'FULLCOMMUNISM', 'Communist', 'communists',\n",
    "      'votethirdparty',\n",
    "      'NeutralPolitics'\n",
    "     ]\n",
    "\n",
    "tmp.filter(tmp.subreddit.isin(li)).sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and save the data from each subrddit separately\n",
    "- First, filter (select where) the data so that we only have the subreddits we care about. Tell pyspark to cache that result for future reuse. This makes the rest of the searches after it faster.\n",
    "    - pyspark actually uses lazy evaluation, so this doesn't run until the first call to `short_reddit.filter()`. That means the first loop is slow, but the loops after it go faster. \n",
    "- Save everything to a tsv file, one per subreddit\n",
    "    - note the headers are off by default\n",
    "    - note this actually saves to a folder full of tsv files (one for each partition). That's a spark thing good for spark but bad for other programs. We'll have to merge them outside this script. (There are ways to merge them here, but if the file is bigger than the JVM memory it throws errors. Easier to fix outside where that doesn't happen.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making short...\n",
      "making politics\n",
      "making Republican\n",
      "making republicans\n",
      "making CollegeRepublicans\n",
      "making askaconservative\n",
      "making askarepublican\n",
      "making Democrat\n",
      "making democrats\n",
      "making CollegeDemocrats\n",
      "making AskDemocrats\n",
      "making GreenParty\n",
      "making Libertarian\n",
      "making AskLibertarians\n",
      "making Liberal\n",
      "making AskALiberal\n",
      "making progressive\n",
      "making socialism\n",
      "making AskASocialist\n",
      "making demsocialist\n",
      "making communism\n",
      "making FULLCOMMUNISM\n",
      "making Communist\n",
      "making communists\n",
      "making votethirdparty\n",
      "making NeutralPolitics\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"making short...\")\n",
    "short_reddit = reddit.filter(reddit.subreddit.isin(li))\n",
    "short_reddit.cache()\n",
    "\n",
    "for l in li:\n",
    "    print 'making', l\n",
    "    result = short_reddit.filter(short_reddit.subreddit == l)\n",
    "    result.write.mode('overwrite').csv(l+'.tsv', sep='\\t', header=True)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same as above, but with a different list of subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|      subreddit|  count|\n",
      "+---------------+-------+\n",
      "|           dogs|1504097|\n",
      "|           cats|1479661|\n",
      "|    Dogtraining| 319811|\n",
      "| CatsStandingUp| 299892|\n",
      "|    dogpictures| 187653|\n",
      "|   StartledCats|  90970|\n",
      "|        CatGifs|  23750|\n",
      "|        puppies|  21052|\n",
      "|dogswearinghats|   7765|\n",
      "|    StuffOnCats|   5432|\n",
      "|            DOG|   3092|\n",
      "|   dogswithjobs|   1046|\n",
      "+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "li = ['cats', 'Meow_irl', 'CatsonGlass', 'CatLoaf', 'Kittens', 'CatGifs', 'StartledCats',\n",
    "      'StuffOnCats', 'CatsStandingUp',\n",
    "      'dogs', 'dogpictures', 'dogswithjobs', 'Dogtraining', 'DOG', 'puppies', \n",
    "      'dogswearinghats'\n",
    "     ]\n",
    "\n",
    "tmp.filter(tmp.subreddit.isin(li)).sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making short...\n",
      "making cats\n",
      "making Meow_irl\n",
      "making CatsonGlass\n",
      "making CatLoaf\n",
      "making Kittens\n",
      "making CatGifs\n",
      "making StartledCats\n",
      "making StuffOnCats\n",
      "making CatsStandingUp\n",
      "making dogs\n",
      "making dogpictures\n",
      "making dogswithjobs\n",
      "making Dogtraining\n",
      "making DOG\n",
      "making puppies\n",
      "making dogswearinghats\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"making short...\")\n",
    "short_reddit = reddit.filter(reddit.subreddit.isin(li))\n",
    "short_reddit.cache()\n",
    "\n",
    "for l in li:\n",
    "    print 'making', l\n",
    "    result = short_reddit.filter(short_reddit.subreddit == l)\n",
    "    result.write.mode('overwrite').csv(l+'.tsv', sep='\\t', header=True)\n",
    "    #df = result.toPandas()\n",
    "    #df.to_csv(l+'.tsv', sep='\\t', index=False)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
